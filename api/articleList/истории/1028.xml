<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<root>
  <title>Основанная Илоном Маском компания OpenAI научила нейросеть придумывать мемы, создавать дизайн и даже писать программы</title>
  <second_title>Все в восторге — но почему в OpenAI говорят, что рано радоваться?</second_title>
  <description>Компания OpenAI, одним из основателей которой выступил Илон Маск, открыла ограниченный доступ к своей новой текстовой модели GPT-3. Некоторые из испытателей смогли использовать эту модель для решения неожиданных — если не сказать невероятных — задач. При этом ее критики (и даже глава OpenAI) предупреждают: еще рано говорить о сильном искусственном интеллекте, мы только в самом начале пути.</description>
  <keywords>новости, политика, расследование, репортаж, интервью, реакция, исследование, опрос, тест, президент, приговор, доллар, нефть, экономика, цены, средства, информация, компания, фото, видео, украина, сепаратисты, война, краткий пересказ, бестселлер</keywords>
  <nameTag>истории</nameTag>
  <name>Meduza</name>
  <url/>
  <date>27.7.2020</date>
  <content>&lt;p&gt;Компания OpenAI, одним из основателей которой выступил Илон Маск, открыла ограниченный доступ к своей новой текстовой модели GPT-3. Некоторые из испытателей смогли использовать эту модель для решения неожиданных — если не сказать невероятных — задач. При этом ее критики (и даже глава OpenAI) предупреждают: еще рано говорить о &lt;span data-id="887180" data-title="Сильный искусственный интеллект" class="FootnoteLink" data-body="&amp;amp;lt;p&amp;amp;gt;ИИ, который позволит компьютерам мыслить и осознавать себя как отдельную личность. &amp;amp;lt;/p&amp;amp;gt;"&gt;сильном искусственном интеллекте&lt;/span&gt;, мы только в самом начале пути.&lt;/p&gt;&lt;h3&gt;Сначала — несколько примеров&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Пример 1.&lt;/strong&gt; Поисковик, который умеет отвечать на вопросы, заданные в свободной форме. И дает ссылку на источник информации. Например, можно спросить, кто убил Махатму Ганди или сколько атомов углерода в молекуле бензола.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Пример 2.&lt;/strong&gt; &lt;a href="https://arr.am/2020/07/14/elon-musk-by-dr-seuss-gpt-3/" target="_blank" rel="noopener"&gt;Приложение&lt;/a&gt;, которое пишет стихи про Илона Маска по их словесному описанию. Например, можно написать «Короткое стихотворение доктора Сьюза про борьбу Маска с Комиссией по ценным бумагам США из-за его твита, в котором утверждалось, что он нашел финансирование для выкупа акций Tesla по 420 долларов». И получить стихотворение, которое (в вольном переводе) будет звучать так:&lt;/p&gt;&lt;p&gt;Илон Маск.&lt;/p&gt;&lt;p&gt;Его скорость высока.&lt;/p&gt;&lt;p&gt;А компания — велика.&lt;/p&gt;&lt;p&gt;Написал он твит,&lt;/p&gt;&lt;p&gt;Акция вверх летит.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Пример 3.&lt;/strong&gt; Плагин для приложения Figma, которым пользуются дизайнеры для создания макетов сайтов и приложений. Вы пишете словесное описание, плагин строит макет. Описание на видео такое: «Приложение с навигационной панелью с иконкой камеры, заголовком Photos и иконкой сообщений. Лента фотографий, где у каждого фото есть иконка пользователя, фото, иконка сердечка и иконка чата». Получилась простая версия инстаграма.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Пример 4&lt;/strong&gt;. Бот, который &lt;a href="https://twitter.com/joshu/status/1285692916623695873" target="_blank" rel="noopener"&gt;описывает&lt;/a&gt; выдуманные мемы. &lt;a href="https://twitter.com/joshu/status/1285693527855435776" target="_blank" rel="noopener"&gt;Например&lt;/a&gt;: «Скептичный голубь с подписью: „Я знаю, что должен больше заниматься, но я не хочу быть единственным голубем на беговой дорожке“». Или &lt;a href="https://twitter.com/joshu/status/1285694484584464388" target="_blank" rel="noopener"&gt;такой&lt;/a&gt;: «Мужчина, отчаянно ищущий воду в пустыне. „Хаха, да, кажется, я умру!“».&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Примеры 5 и 6&lt;/strong&gt;. Приложения, которые пишут код на разных языках программирования. Например, так можно собрать веб-страницу — нужно просто описать словами, что вы хотите получить, например: «Большая надпись „Добро пожаловать в мою рассылку“ и синяя кнопка с надписью „подписаться“».&lt;/p&gt;&lt;p&gt;Такое же &lt;a href="https://twitter.com/jsngr/status/1284874360952692736" target="_blank" rel="noopener"&gt;можно&lt;/a&gt; провернуть с кодом на SwiftUI, позволяющим собирать приложения для айфонов и айпадов. Здесь GPT-3 получила один пример программы на SwiftUI, после чего смогла без ошибок написать свое приложение.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Пример 7.&lt;/strong&gt; &lt;a href="https://vimeo.com/427943407/98fe5258a7" target="_blank" rel="noopener"&gt;Интерфейс&lt;/a&gt; командной строки, который понимает текст, написанный простым языком, — и превращает его в стандартные Unix-команды с нужными параметрами. Вы пишете «сколько свободного места осталось на жестком диске», а GPT-3 подбирает терминальную команду, которая позволяет это вычислить. Или вы пишете: «Сколько файлов с Python-кодом в текущей папке?» — а затем уточняете: «Сколько строк кода в них?» И GPT-3 генерирует команды, позволяющие получить оба этих ответа.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Пример 8.&lt;/strong&gt; Функция для экселя, которая сама все понимает. Например, вы создаете табличку со столбцами «город» и «население», вписываете город — а количество жителей подставит GPT-3.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Примеры 9, 10, 11, 12 и 13. &lt;/strong&gt;Создание &lt;a href="http://www.bemmu.com/gpt3-presentation" target="_blank" rel="noopener"&gt;презентаций&lt;/a&gt; по их текстовому описанию,&lt;strong&gt; &lt;/strong&gt;генерирование &lt;a href="https://twitter.com/DonCubed/status/1284908940149395456?s=20" target="_blank" rel="noopener"&gt;резюме&lt;/a&gt;, &lt;a href="https://twitter.com/QasimMunye/status/1278750809094750211" target="_blank" rel="noopener"&gt;прохождение&lt;/a&gt; сложных медицинских тестов с обоснованием ответа, &lt;a href="https://twitter.com/paraschopra/status/1284423029443850240" target="_blank" rel="noopener"&gt;«общение»&lt;/a&gt; с известными людьми на заданную тему («Стивен Хокинг объясняет, что происходит в черной дыре за горизонтом событий») и &lt;a href="https://twitter.com/Learn_Awesome/status/1286189729826738176" target="_blank" rel="noopener"&gt;создание&lt;/a&gt; тестов на заданную тему с проверкой введенных ответов.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Пример 14.&lt;/strong&gt; &lt;a href="https://twitter.com/Merzmensch/status/1283419366143524866?s=20" target="_blank" rel="noopener"&gt;Разговор о боге&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;Как это все работает?&lt;/h3&gt;&lt;p&gt;Примеры выше появились благодаря двум компонентам. Первый — GPT-3, языковая модель, обученная почти на &lt;a href="https://www.wired.com/story/ai-text-generator-gpt-3-learning-language-fitfully/" target="_blank" rel="noopener"&gt;триллионе&lt;/a&gt; слов, собранных по всему интернету: в Википедии, новостях, обучающих курсах по C++ и оцифрованных книгах. Как &lt;a href="https://minimaxir.com/2020/07/gpt3-expectations/" target="_blank" rel="noopener"&gt;отмечает&lt;/a&gt; аналитик данных BuzzFeed Макс Вульф, GPT-3 обучалась в октябре 2019 года, поэтому она не знает о ситуации с COVID-19 в мире.&lt;/p&gt;&lt;p&gt;Говоря общо, языковая модель — это система, предсказывающая существование того или иного предложения (как набора слов). The Next Web &lt;a href="https://thenextweb.com/neural/2020/07/23/openais-new-gpt-3-language-explained-in-under-3-minutes-syndication/" target="_blank" rel="noopener"&gt;приводит&lt;/a&gt; такой пример: языковая модель, скорее всего, скажет, что у предложения «я выгулял собаку» больше вероятность существования, чем у «я выгулял банан». Чтобы обучить языковую модель, исследователи убирают из обучающего текста случайные слова и заставляют ее «учиться» заполнять пробелы.&lt;/p&gt;&lt;p&gt;GPT-3 получилась огромной: в ней 175 миллиардов параметров, то есть переменных, которые нейросеть оптимизирует в процессе обучения. У ее предшественника, GPT-2, было 1,5 миллиарда параметров, а в случае с языковыми моделями размер имеет значение, &lt;a href="https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/" target="_blank" rel="noopener"&gt;отмечает&lt;/a&gt; MIT Technology Review. Огромный набор данных и количество параметров заставляют GPT-3 выглядеть «умной» и «человекоподобной».&lt;/p&gt;&lt;p&gt;Как объяснил «Медузе» руководитель лаборатории машинного обучения «Яндекса» Александр Крайнов, то, что одна и та же модель может и писать код, и писать стихи, и выдумывать сценарии, — неудивительно. «И код, и сценарии писались людьми, которые до этого „воспитывались“ на обычных текстах. А значит и в них в некой мере есть те же закономерности, те же принципы», — рассказал он.&lt;/p&gt;&lt;p&gt;Второй компонент, используемый в примерах из этого текста, — это The API. Само по себе API — это термин, обозначающий любой программный интерфейс. Свой API есть у твиттера, фейсбука и «Медузы», они позволяют программам (будь то официальное iOS-приложение или чат-бот) загружать чужие посты или новости и публиковать свои твиты.&lt;/p&gt;&lt;p&gt;Но OpenAI назвала свой продукт The API, пытаясь подчеркнуть его особое положение, показать, что это API с самой большой буквы A. Работа с ним проста: пользователь вводит какой-то текст, а система с помощью GPT-3 пишет продолжение. При желании систему можно обучить, показав ей несколько примеров «текст — продолжение». И в этом замечательность огромной языковой модели: ее не нужно прицельно учить определенной задаче, вроде перевода с русского языка на английский или написания кода. Достаточно пары примеров, и она уже начинает делать похожие вещи — например, создавать тексты программ.&lt;/p&gt;&lt;h3&gt;Что об этом говорят?&lt;/h3&gt;&lt;p&gt;&lt;a href="https://twitter.com/ID_AA_Carmack/status/1284901555917987847" target="_blank" rel="noopener"&gt;Джон Кармак&lt;/a&gt;, разработчик самой первой Doom и консультирующий технический директор Oculus, в последние годы занятый разработкой искусственного интеллекта: «Я раньше говорил, что исследователи искусственного интеллекта почему-то игнорируют автоматизацию программирования, и я подозревал, что это подсознательное стремление к самосохранению. Недавнее, почти случайное открытие, что GPT-3 может в каком-то смысле писать код, вызывает легкую дрожь».&lt;/p&gt;&lt;p&gt;&lt;a href="https://delian.substack.com/p/quick-thoughts-on-gpt3" target="_blank" rel="noopener"&gt;Делин Аспарухов&lt;/a&gt;, инвестиционный директор в Founders Fund: «Моя любимая аналогия, объясняющая GPT-3, звучит так: iPhone уместил знания всего мира в ваш карман, а GPT-3 дает доступ к 10 тысячам кандидатов наук, готовых пообщаться с вами на заданную тему. 30 лет назад Стив Джобс описал компьютеры как „велосипеды для ума“. Я б сказал, что даже в нынешнем состоянии GPT-3 — это „гоночный автомобиль для ума“».&lt;/p&gt;&lt;p&gt;&lt;a href="https://twitter.com/anderssandberg/status/1285104499531698176" target="_blank" rel="noopener"&gt;Андерс Сэндберг&lt;/a&gt;, старший научный сотрудник в Оксфордском университете: «Для меня главная история с GPT-3 не в том, что [эта система] умна — она не умнее груды камней, — а в том, что груда камней может делать многие вещи, для которых, как нам казалось, нужно быть умным. Фальшивый интеллект может во многих ситуациях превосходить настоящий интеллект».&lt;/p&gt;&lt;p&gt;&lt;a href="https://twitter.com/togelius/status/1284131360857358337" target="_blank" rel="noopener"&gt;Джулиан Тогелиус&lt;/a&gt;, директор Лаборатории инноваций в сфере игр в Политехническом институте Нью-Йоркского университета: «GPT-3 часто пишет как умный студент, который не подготовился дома и пытается как-то отболтаться на экзамене. Немного широко известных фактов, немного полуправды и немного откровенной лжи, собранных в то, что на первый взгляд выглядит как ровный рассказ».&lt;/p&gt;&lt;p&gt;&lt;a href="https://twitter.com/sama/status/1284922296348454913" target="_blank" rel="noopener"&gt;Cэм Альтман&lt;/a&gt;, гендиректор OpenAI: «Внимание к GPT-3 слишком раздуто. Она впечатляет (спасибо за комплименты!), но у нее остаются серьезные недостатки, и иногда она совершает очень глупые ошибки. ИИ изменит мир, но GPT-3 — это первое приближение. Нам еще многое предстоит выяснить».&lt;/p&gt;&lt;h3&gt;В чем проблема?&lt;/h3&gt;&lt;p&gt;Примеры, которые мы видим в твиттере и блогах, — это лучшее, на что способны GPT-3 и The API: люди скорее будут публиковать успешные ответы системы, оставляя за скобками бессмыслицу, которую она тоже выдает. Аррам Сабети, автор (или «автор») стихов про Илона Маска, написанных от лица доктора Сьюза, &lt;a href="https://arr.am/2020/07/14/elon-musk-by-dr-seuss-gpt-3/" target="_blank" rel="noopener"&gt;рассказывает&lt;/a&gt; в своем блоге, что на создание пяти стихотворений у него ушло несколько часов проб и ошибок: GPT-3 не очень хорошо рифмует строки, так что приходилось многократно формулировать и вводить запросы, чтобы получить удовлетворительные результаты.&lt;/p&gt;&lt;p&gt;Другая проблема более фундаментальная: хоть GPT-3 часто отвечает на запросы так, словно она «понимает» смысл сказанного, на деле никакой смысл не анализируется — система, как уже было сказано, просто пытается предсказать наиболее вероятное продолжение текста. «У нее нет никакой внутренней модели нашего мира, или какого-либо мира, поэтому она не может рассуждать, поскольку для этого понадобилась бы такая модель», — &lt;a href="https://www.wired.com/story/ai-text-generator-gpt-3-learning-language-fitfully/" target="_blank" rel="noopener"&gt;сказала&lt;/a&gt; Wired профессор Института Санта-Фе и автор книги об искусственном интеллекте Мелани Митчелл.&lt;/p&gt;&lt;p&gt;Во время своих экспериментов она &lt;a href="https://twitter.com/MelMitchell1/status/1285274169240768512" target="_blank" rel="noopener"&gt;просила&lt;/a&gt; GPT-3 восстановить набор букв по аналогии: «Если &lt;mark&gt;a x x d&lt;/mark&gt; превращается в &lt;mark&gt;a b c d&lt;/mark&gt;, то во что превращается &lt;mark&gt;p x r s&lt;/mark&gt;?» (правильный ответ — &lt;mark&gt;p q r s&lt;/mark&gt;). С некоторыми из таких задач (включая ту, что приведена выше) система справлялась, но с другими аналогичными — например, с рядами &lt;mark&gt;a x c x e&lt;/mark&gt; и &lt;mark&gt;x q r s t&lt;/mark&gt;, — уже нет.&lt;/p&gt;&lt;p&gt;О том, что система не понимает смысла текста, рассказал «Медузе» и Александр Крайнов из «Яндекса»: «Система продолжает текст исходя из общих закономерностей того, как обычно продолжается текст. Есть такая детская шутка, когда предлагают быстро и не думая отвечать на простые вопросы, и спрашивают „Что пьет корова?“. Обычно отвечают „молоко“. Такие ответы на большой скорости и не думая очень похожи на работу нейросети».&lt;/p&gt;&lt;p&gt;Еще одна проблема характерна для нейросетей, обучающихся на информации, доступной в интернете: они начинают повторять общепринятые стереотипы и иногда звучат крайне неэтично. Один из самых ярких примеров произошел в 2016 году: нейросеть от Microsoft во время общения с пользователями твиттера быстро &lt;a href="https://meduza.io/shapito/2016/03/24/iskusstvennyy-intellekt-ot-microsoft-za-sutki-polyubil-gitlera-i-voznenavidel-feministok" target="_blank" rel="noopener"&gt;перешла&lt;/a&gt; к высказываниям в духе «Гитлер был прав, я ненавижу евреев».&lt;/p&gt;&lt;p&gt;GPT-3 порой ведет себя похожим образом. Когда модель &lt;a href="https://twitter.com/an_open_mind/status/1284487376312709120" target="_blank" rel="noopener"&gt;попросили&lt;/a&gt; дописать текст, начинавшийся всего с одного слова «евреи», получилось «евреи большую часть времени любят деньги». В OpenAI говорят, что работают над системой, которая будет отфильтровывать такие результаты; уже сейчас в ответ на некоторые запросы можно увидеть предупреждение: «Наша система установила, что сгенерированный контент небезопасен, так как может содержать явно политический или оскорбительный текст. Эта система экспериментальная и может ошибаться».&lt;/p&gt;&lt;p&gt;Наконец, еще одна важная проблема — что GPT-3 часто генерирует настолько связный текст, что в нем трудно увидеть неправду (если она есть). Когда журналист Wired &lt;a href="https://www.wired.com/story/ai-text-generator-gpt-3-learning-language-fitfully/" target="_blank" rel="noopener"&gt;попросил&lt;/a&gt; систему написать его некролог, основываясь на примерах из газеты, GPT-3 хорошо повторила формат, но смешала реальные факты, вроде прошлых мест работы героя, с выдумкой — именами членов его семьи и причиной смерти. «На удивление было трогательно читать, как он умер, когда ему (будет) 47 лет, и что он оставил впечатление „приятного, трудолюбивого и уважаемого в своей сфере“ человека», — пишет автор материала.&lt;/p&gt;&lt;p&gt;Разработчик Парас Чопра, создавший поисковик на базе GPT-3 (первый пример в этом материале), &lt;a href="https://twitter.com/paraschopra/status/1285802985990139906" target="_blank" rel="noopener"&gt;объясняет&lt;/a&gt;: «Один из самых больших рисков GPT-3 в том, что он так хорошо работает в большинстве случаев. В крайних случаях, когда он выдает чепуху, люди все равно ему поверят. Например, я не знаю, кто изобрел стеклянные бутылки, но GPT-3 говорит, что египтяне. Так что, видимо, да ¯\_(ツ)_/¯».&lt;/p&gt;&lt;h3&gt;Что дальше?&lt;/h3&gt;&lt;p&gt;Сейчас разработчики должны оставлять заявку на сайте OpenAI, чтобы получить доступ к The API. Сама система — для тех, кто получил приглашение, — пока бесплатна, но в будущем компания планирует запустить ее коммерческую версию. Сколько она будет стоить, неизвестно.&lt;/p&gt;</content>
</root>